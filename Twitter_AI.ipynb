{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": [
        "Nj6aMXKApKyR"
      ],
      "authorship_tag": "ABX9TyPbl7NgGozIn5fo3U1FXjnZ",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/TeneikaAskew/tResourceGPT/blob/main/Twitter_AI.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Twitter"
      ],
      "metadata": {
        "id": "yAyaDhFNasxz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "\n",
        "def save_and_push_to_github(commit_message=\"Auto-save from Google Colab\"):\n",
        "    # Add all changes\n",
        "    os.system(\"git add .\")\n",
        "    # Commit changes\n",
        "    os.system(f'git commit -m \"{commit_message}\"')\n",
        "    # Push changes to the GitHub repository\n",
        "    os.system(\"git push origin main\")  # Use 'master' if your default branch is named 'master'"
      ],
      "metadata": {
        "id": "esK_RxYxE1Dz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from IPython.core.magic import register_line_cell_magic\n",
        "\n",
        "@register_line_cell_magic\n",
        "def autosave(line, cell):\n",
        "    # Execute the cell\n",
        "    exec(cell)\n",
        "    # After execution, save and push to GitHub\n",
        "    save_and_push_to_github(\"Autosave after cell execution\")\n"
      ],
      "metadata": {
        "id": "8OXTdkHdE5o5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## ETL"
      ],
      "metadata": {
        "id": "Nj6aMXKApKyR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Step 1: Mount Google Drive\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "# Step 2: Define the file path (update this path to your file location in Google Drive)\n",
        "js_file_path = '/content/drive/MyDrive/TwitterLinkedIn_AI_ML_Project/tweets.js'  # Update with the correct path\n",
        "csv_file_path = '/content/drive/MyDrive/TwitterLinkedIn_AI_ML_Project/converted_tweets.csv'\n",
        "\n",
        "# Step 3: Load and parse the JSON directly from the file\n",
        "import json\n",
        "from datetime import datetime\n",
        "import pytz\n",
        "import pandas as pd\n",
        "\n",
        "with open(js_file_path, 'r', encoding='utf-8') as file:\n",
        "    content = file.read().split('=', 1)[-1].strip()  # Remove 'window.YTD.tweets.part0 ='\n",
        "    data = json.loads(content.rstrip(';'))  # Remove trailing semicolon if present\n",
        "\n",
        "# Step 4: Process the JSON data to extract relevant tweet information\n",
        "tweet_data = []\n",
        "for tweet in data:\n",
        "    tweet_info = tweet.get('tweet', {})\n",
        "\n",
        "    # Extract specific fields from each tweet\n",
        "    created_at_utc = tweet_info.get(\"created_at\")\n",
        "    if created_at_utc:\n",
        "        # Convert created_at to EST\n",
        "        utc_time = datetime.strptime(created_at_utc, '%a %b %d %H:%M:%S +0000 %Y')\n",
        "        est_time = utc_time.replace(tzinfo=pytz.utc).astimezone(pytz.timezone('US/Eastern'))\n",
        "        est_time_str = est_time.strftime('%Y-%m-%d %H:%M:%S')\n",
        "    else:\n",
        "        est_time_str = None\n",
        "\n",
        "    flattened_tweet = {\n",
        "        \"tweet_id\": tweet_info.get(\"id_str\"),\n",
        "        \"created_at\": created_at_utc,\n",
        "        \"created_at_est\": est_time_str,  # New column with EST time\n",
        "        \"full_text\": tweet_info.get(\"full_text\"),\n",
        "        \"favorite_count\": tweet_info.get(\"favorite_count\"),\n",
        "        \"retweet_count\": tweet_info.get(\"retweet_count\"),\n",
        "        \"in_reply_to_screen_name\": tweet_info.get(\"in_reply_to_screen_name\"),\n",
        "        \"lang\": tweet_info.get(\"lang\"),\n",
        "        \"source\": tweet_info.get(\"source\"),\n",
        "        \"user_mentions\": [\n",
        "            mention.get(\"screen_name\") for mention in tweet_info.get(\"entities\", {}).get(\"user_mentions\", [])\n",
        "        ]\n",
        "    }\n",
        "    tweet_data.append(flattened_tweet)\n",
        "\n",
        "# Convert to DataFrame\n",
        "df = pd.DataFrame(tweet_data)\n",
        "\n",
        "# Step 5: Save the DataFrame as CSV\n",
        "df.to_csv(csv_file_path, index=False)\n",
        "\n",
        "print(f'File successfully converted and saved at: {csv_file_path}')\n",
        "\n",
        "# Load and preprocess the data\n",
        "file_path = '/content/drive/MyDrive/TwitterLinkedIn_AI_ML_Project/converted_tweets.csv'\n",
        "df = pd.read_csv(file_path)"
      ],
      "metadata": {
        "id": "kgQBnVU0dkdq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Logistic Regression"
      ],
      "metadata": {
        "id": "VbnTtGrJqONH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import classification_report, accuracy_score\n",
        "import re\n",
        "\n",
        "\n",
        "# Step 0: Filter to items with a created date of October 1, 2019 or later\n",
        "df['created_at'] = pd.to_datetime(df['created_at'], errors='coerce')\n",
        "df = df[df['created_at'] >= '2019-10-01']\n",
        "\n",
        "# Assigning labels for `resource_type` and `career_area` based on keywords\n",
        "resource_labels = {\n",
        "    \"entrepreneur\": [\"entrepreneur\", \"founder\", \"business\", \"startup\", \"entrepreneurship\", \"funding\",\"accelerator\"],\n",
        "    \"scholarship\": [\"scholarship\"],\n",
        "    \"bootcamp\": [\"bootcamp\"],\n",
        "    \"resume\": [\"resume\"],\n",
        "    \"apprenticeship\": [\"apprenticeship\"],\n",
        "    \"job\": [\"job opening\", \"hiring\", \"position\"],\n",
        "    \"upskilling\": [\"upskill\", \"learning\", \"training\"],\n",
        "    \"conferences\": [\"conference\", \"event\", \"seminar\"],\n",
        "    \"general_discussion\": [\"discussion\", \"opinion\", \"thoughts\"]\n",
        "}\n",
        "\n",
        "career_labels = {\n",
        "    \"Entrepreneur\": [\"entrepreneur\", \"founder\", \"business\", \"startup\", \"entrepreneurship\", \"funding\",\"accelerator\"],\n",
        "    \"Data Analytics\": [\"data analytics\", \"data analysis\"],\n",
        "    \"AI\": [\"artificial intelligence\", \"ai\"],\n",
        "    \"Data Engineering\": [\"data engineering\", \"data pipeline\"],\n",
        "    \"ServiceNow\": [\"servicenow\"],\n",
        "    \"Salesforce\": [\"salesforce\"],\n",
        "    \"Cloud\": [\"cloud\", \"aws\", \"azure\", \"gcp\"],\n",
        "    \"UX\": [\"ux\", \"user experience\"],\n",
        "    \"Product Management\": [\"product management\"],\n",
        "    \"Product Design\": [\"product design\"],\n",
        "    \"Project Management\": [\"project management\", \"pmp\"],\n",
        "    \"Digital Marketing\": [\"digital marketing\"],\n",
        "    \"Software & Systems Engineering\": [\"software engineering\", \"systems engineering\"],\n",
        "    \"Data\": [\"data\"],\n",
        "    \"Software or Web Development\": [\"software development\", \"web development\"],\n",
        "    \"Tech Sales\": [\"tech sales\"]\n",
        "}\n",
        "\n",
        "# Assign labels based on keywords\n",
        "def assign_labels(text, label_dict):\n",
        "    for label, keywords in label_dict.items():\n",
        "        if any(keyword.lower() in str(text).lower() for keyword in keywords):\n",
        "            return label\n",
        "    return None\n",
        "\n",
        "df['resource_type'] = df['full_text'].apply(lambda x: assign_labels(x, resource_labels))\n",
        "df['career_area'] = df['full_text'].apply(lambda x: assign_labels(x, career_labels))\n",
        "\n",
        "# Extract links to a new field\n",
        "df['resource_link'] = df['full_text'].str.extract(r'(https?://\\S+)')\n",
        "\n",
        "# Prepare data for model training - drop rows without labels\n",
        "labeled_df = df.dropna(subset=['resource_type', 'career_area'])\n"
      ],
      "metadata": {
        "id": "jsoIfyFD2x-6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Step 2: Text vectorization using TF-IDF\n",
        "tfidf = TfidfVectorizer(stop_words='english', max_features=3000)\n",
        "X = tfidf.fit_transform(labeled_df['full_text'])\n",
        "\n",
        "# Encode the labels\n",
        "y_resource = labeled_df['resource_type']\n",
        "y_career = labeled_df['career_area']\n",
        "\n",
        "# Split data for resource type prediction\n",
        "X_train_res, X_test_res, y_train_res, y_test_res = train_test_split(X, y_resource, test_size=0.2, random_state=42)\n",
        "X_train_career, X_test_career, y_train_career, y_test_career = train_test_split(X, y_career, test_size=0.2, random_state=42)\n",
        "\n",
        "# Step 3: Train the classifier for resource type\n",
        "resource_model = LogisticRegression(max_iter=200)\n",
        "resource_model.fit(X_train_res, y_train_res)\n",
        "\n",
        "# Train the classifier for career area\n",
        "career_model = LogisticRegression(max_iter=200)\n",
        "career_model.fit(X_train_career, y_train_career)\n",
        "\n",
        "# Step 4: Evaluate both models\n",
        "y_pred_res = resource_model.predict(X_test_res)\n",
        "y_pred_career = career_model.predict(X_test_career)\n",
        "\n",
        "# Classification reports\n",
        "print(\"Resource Type Classification Report\")\n",
        "print(classification_report(y_test_res, y_pred_res))\n",
        "print(f\"Resource Type Accuracy: {accuracy_score(y_test_res, y_pred_res):.2f}\")\n",
        "\n",
        "print(\"\\nCareer Area Classification Report\")\n",
        "print(classification_report(y_test_career, y_pred_career))\n",
        "print(f\"Career Area Accuracy: {accuracy_score(y_test_career, y_pred_career):.2f}\")\n"
      ],
      "metadata": {
        "id": "a3xgAjjqdlIL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Accuracy:** 87% for Resource Type, 79% for Career Area.\n",
        "\n",
        "**Strengths:** High precision for specific categories like \"entrepreneur\" and \"upskilling\" in Resource Type.\n",
        "\n",
        "**Weaknesses:** Low recall for less common categories, with some classes (like \"general_discussion\" in Career Area) showing zero recall.\n",
        "\n",
        "**Interpretation:** This model performs well for high-frequency labels but struggles with underrepresented categories, especially in Career Area."
      ],
      "metadata": {
        "id": "IXQLAlPLJdl7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# prompt: show this in a df y_test_career, y_pred_career\n",
        "pd.DataFrame({'y_test_career': y_test_career, 'y_pred_career': y_pred_career})"
      ],
      "metadata": {
        "id": "XpwwyVXzriLR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Expansion of Labels"
      ],
      "metadata": {
        "id": "ljVzl8ylqtjd"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Revision of labels to consistently refine after each run"
      ],
      "metadata": {
        "id": "QanZrt5r5DPR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Assigning labels for `resource_type` and `career_area` based on keywords\n",
        "resource_labels = {\n",
        "    \"entrepreneur\": [\"entrepreneur\", \"founder\", \"business\", \"startup\", \"entrepreneurship\", \"funding\",\"accelerator\"],\n",
        "    \"scholarship\": [\"scholarship\"],\n",
        "    \"bootcamp\": [\"bootcamp\", \"program\", \"academy\", \"certificate\"],\n",
        "    \"resume\": [\"resume\", \"cv\", \"curriculum vitae\"],\n",
        "    \"job\": [\"job opening\", \"hiring\", \"position\", \"apprenticeship\", \"internship\", \"apprentice\", \"career opportunity\", \"job posting\"],\n",
        "    \"upskilling\": [\"upskill\", \"learning\", \"training\", \"skill development\", \"course\", \"certification\"],\n",
        "    \"conferences\": [\"conference\", \"event\", \"seminar\", \"webinar\", \"meetup\", \"workshop\", \"fireside chat\", \"fireside\", \"panel\", \"summit\"],\n",
        "    \"general_discussion\": [\"discussion\", \"opinion\", \"thoughts\", \"general\", \"comment\", \"feedback\", \"insight\"]\n",
        "}\n",
        "\n",
        "career_labels = {\n",
        "    \"Entrepreneur\": [\"entrepreneur\", \"founder\", \"business\", \"startup\", \"entrepreneurship\", \"funding\",\"accelerator\"],\n",
        "    \"Data Analytics\": [\"data analytics\", \"data analysis\", \"business intelligence\", \"BI\", \"data analyst\"],\n",
        "    \"AI\": [\"artificial intelligence\", \"ai\", \"machine learning\", \"ML\", \"deep learning\"],\n",
        "    \"Data Engineering\": [\"data engineering\", \"data pipeline\", \"data engineer\", \"data infrastructure\", \"ETL\", \"big data\"],\n",
        "    \"ServiceNow\": [\"servicenow\"],\n",
        "    \"Students\": [\"student\", \"students\", \"early career\", \"student\"],\n",
        "    \"Salesforce\": [\"salesforce\", \"crm\"],\n",
        "    \"Cloud\": [\"cloud\", \"aws\", \"azure\", \"gcp\", \"oracle\", \"cloud computing\"],\n",
        "    \"Cybersecurity\": [\"cyber\", \"cybersecurity\", \"networking\", \"linux\", \"soc\", \"cyber security\", \"security\", \"penetration testing\"],\n",
        "    \"UX\": [\"ux\", \"user experience\", \"ui\", \"design thinking\", \"interface\", \"human centered\", \"design\", \"ui\"],\n",
        "    \"Product Management\": [\"product management\", \"product manager\", \"product\", \"agile\"],\n",
        "    \"Product Design\": [\"product design\", \"product development\"],\n",
        "    \"Project Management\": [\"project management\", \"pmp\", \"project planning\"],\n",
        "    \"Digital Marketing\": [\"digital marketing\", \"social media\", \"seo\", \"content marketing\"],\n",
        "    \"Software & Systems Engineering\": [\"software engineering\", \"systems engineering\", \"embedded systems\", \"systems architect\"],\n",
        "    \"Data\": [\"data\", \"data science\", \"statistics\"],\n",
        "    \"Software or Web Development\": [\"software development\", \"web development\", \"devops\", \"frontend\", \"backend\", \"full stack\", \"javascript\", \"react\"],\n",
        "    \"Tech Sales\": [\"tech sales\", \"technical sales\", \"business development\"],\n",
        "    \"Finance\": [\"finance\", \"financial\", \"accounting\", \"investment\", \"capital\"],\n",
        "    \"Tech\": [\"tech\", \"technical\", \"technology\", \"FAANG\", \"Silicon Valley\"],\n",
        "    \"Non-Tech\": [\"nontech\", \"non-tech\", \"non technical\"],\n",
        "    \"GovTech\": [\"govtech\", \"gov-tech\", \"irs\", \"fema\", \"dod\", \"digital corps\", \"coding it forward\", \"digital service\", \"gsa\", \"tts\", \"public sector\"]\n",
        "}\n",
        "\n",
        "# Assign labels based on keywords\n",
        "def assign_labels(text, label_dict):\n",
        "    for label, keywords in label_dict.items():\n",
        "        if any(keyword.lower() in str(text).lower() for keyword in keywords):\n",
        "            return label\n",
        "    return None\n",
        "\n",
        "df['resource_type'] = df['full_text'].apply(lambda x: assign_labels(x, resource_labels))\n",
        "df['career_area'] = df['full_text'].apply(lambda x: assign_labels(x, career_labels))\n",
        "\n",
        "# Extract links to a new field\n",
        "df['resource_link'] = df['full_text'].str.extract(r'(https?://\\S+)')\n",
        "\n",
        "# Prepare data for model training - drop rows without labels\n",
        "labeled_df = df.dropna(subset=['resource_type', 'career_area'])\n"
      ],
      "metadata": {
        "id": "WChdnSGV241m"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# Step 2: Text vectorization using TF-IDF\n",
        "tfidf = TfidfVectorizer(stop_words='english', max_features=3000)\n",
        "X = tfidf.fit_transform(labeled_df['full_text'])\n",
        "\n",
        "# Encode the labels\n",
        "y_resource = labeled_df['resource_type']\n",
        "y_career = labeled_df['career_area']\n",
        "\n",
        "# Split data for resource type prediction\n",
        "X_train_res, X_test_res, y_train_res, y_test_res = train_test_split(X, y_resource, test_size=0.2, random_state=42)\n",
        "X_train_career, X_test_career, y_train_career, y_test_career = train_test_split(X, y_career, test_size=0.2, random_state=42)\n",
        "\n",
        "# Step 3: Train the classifier for resource type\n",
        "resource_model = LogisticRegression(max_iter=200)\n",
        "resource_model.fit(X_train_res, y_train_res)\n",
        "\n",
        "# Train the classifier for career area\n",
        "career_model = LogisticRegression(max_iter=200)\n",
        "career_model.fit(X_train_career, y_train_career)\n",
        "\n",
        "# Step 4: Evaluate both models\n",
        "y_pred_res = resource_model.predict(X_test_res)\n",
        "y_pred_career = career_model.predict(X_test_career)\n",
        "\n",
        "# Classification reports\n",
        "print(\"Resource Type Classification Report\")\n",
        "print(classification_report(y_test_res, y_pred_res))\n",
        "print(f\"Resource Type Accuracy: {accuracy_score(y_test_res, y_pred_res):.2f}\")\n",
        "\n",
        "print(\"\\nCareer Area Classification Report\")\n",
        "print(classification_report(y_test_career, y_pred_career))\n",
        "print(f\"Career Area Accuracy: {accuracy_score(y_test_career, y_pred_career):.2f}\")\n"
      ],
      "metadata": {
        "id": "W3dG-6mco2wT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Accuracy:** 89% for Resource Type, 64% for Career Area.\n",
        "\n",
        "**Strengths:** Improved handling of certain career categories, especially with better precision for \"AI\" and \"Cloud.\"\n",
        "\n",
        "**Weaknesses:** Many classes in Career Area (e.g., \"Data Engineering\" and \"GovTech\") are still not well captured, with low recall across some categories.\n",
        "\n",
        "**Interpretation:** While Resource Type classification improved slightly, the added complexity reduced accuracy for Career Area, indicating overfitting on expanded labels without sufficient data for each category."
      ],
      "metadata": {
        "id": "oY15rm__J6MO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# prompt: show this in a df y_test_career, y_pred_career\n",
        "pd.DataFrame({'y_test_career': y_test_career, 'y_pred_career': y_pred_career})"
      ],
      "metadata": {
        "id": "YU0o6DzorKJq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Multi-Class Model"
      ],
      "metadata": {
        "id": "yG_0bZGWqh_P"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.multioutput import MultiOutputClassifier\n",
        "from sklearn.preprocessing import MultiLabelBinarizer\n",
        "\n",
        "# Function to assign multiple labels based on keywords\n",
        "def assign_multi_labels(text, label_dict):\n",
        "    labels = []\n",
        "    for label, keywords in label_dict.items():\n",
        "        if any(keyword.lower() in str(text).lower() for keyword in keywords):\n",
        "            labels.append(label)\n",
        "    return labels if labels else [\"general_discussion\"]\n",
        "\n",
        "# Load and preprocess the data\n",
        "file_path = '/content/drive/MyDrive/TwitterLinkedIn_AI_ML_Project/converted_tweets.csv'\n",
        "df = pd.read_csv(file_path)\n",
        "\n",
        "# Filter to items with a created date of October 1, 2019 or later\n",
        "df['created_at'] = pd.to_datetime(df['created_at'], errors='coerce')\n",
        "df = df[df['created_at'] >= '2019-10-01']\n",
        "\n",
        "\n",
        "# Apply multi-label assignment functions\n",
        "df['resource_type'] = df['full_text'].apply(lambda x: assign_multi_labels(x, resource_labels))\n",
        "df['career_area'] = df['full_text'].apply(lambda x: assign_multi_labels(x, career_labels))\n",
        "\n",
        "# Convert labels to multi-label binary format using MultiLabelBinarizer\n",
        "mlb_resource = MultiLabelBinarizer()\n",
        "mlb_career = MultiLabelBinarizer()\n",
        "\n",
        "y_resource = mlb_resource.fit_transform(df['resource_type'])\n",
        "y_career = mlb_career.fit_transform(df['career_area'])\n",
        "\n",
        "# Extract links to a new field\n",
        "df['resource_link'] = df['full_text'].str.extract(r'(https?://\\S+)')"
      ],
      "metadata": {
        "id": "bNamQYTuLEKs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Text vectorization using TF-IDF\n",
        "tfidf = TfidfVectorizer(stop_words='english', max_features=1000)\n",
        "X = tfidf.fit_transform(df['full_text'])\n",
        "\n",
        "# Split data for resource type prediction\n",
        "X_train_res, X_test_res, y_train_res, y_test_res = train_test_split(X, y_resource, test_size=0.2, random_state=42)\n",
        "X_train_career, X_test_career, y_train_career, y_test_career = train_test_split(X, y_career, test_size=0.2, random_state=42)\n",
        "\n",
        "# Train multi-label classifier for resource type using Logistic Regression\n",
        "resource_model = MultiOutputClassifier(LogisticRegression(max_iter=200))\n",
        "resource_model.fit(X_train_res, y_train_res)\n",
        "\n",
        "# Train multi-label classifier for career area using Logistic Regression\n",
        "career_model = MultiOutputClassifier(LogisticRegression(max_iter=200))\n",
        "career_model.fit(X_train_career, y_train_career)\n",
        "\n",
        "# Evaluate both models\n",
        "y_pred_res = resource_model.predict(X_test_res)\n",
        "y_pred_career = career_model.predict(X_test_career)\n",
        "\n",
        "# Display classification reports\n",
        "print(\"Resource Type Classification Report\")\n",
        "print(classification_report(y_test_res, y_pred_res, target_names=mlb_resource.classes_))\n",
        "\n",
        "print(\"\\nCareer Area Classification Report\")\n",
        "print(classification_report(y_test_career, y_pred_career, target_names=mlb_career.classes_))\n"
      ],
      "metadata": {
        "id": "BXTHbw9UrcDu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Accuracy:** 95% for Resource Type (samples avg), 79% for Career Area (samples avg).\n",
        "\n",
        "**Strengths:** Highest accuracy and balanced recall for Resource Type, good micro-average recall for Career Area. This model shows strong performance for multi-label classification, especially for labels that appear in combination.\n",
        "\n",
        "**Weaknesses:** Some Career Area categories like \"Non-Tech,\" \"Digital Marketing,\" and \"Finance\" still have low recall and F1-scores.\n",
        "\n",
        "**Interpretation:** This model benefits from multi-label flexibility, allowing each tweet to be assigned multiple resource and career labels, resulting in more accurate predictions. However, Career Area categories with limited training samples still suffer in performance."
      ],
      "metadata": {
        "id": "2acKvgLqKOYh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# prompt: show the df with the predicted labels\n",
        "\n",
        "# Predict labels for the entire dataset\n",
        "y_pred_res_all = resource_model.predict(X)\n",
        "y_pred_career_all = career_model.predict(X)\n",
        "\n",
        "# Convert predicted labels back to original format\n",
        "predicted_resource_labels = mlb_resource.inverse_transform(y_pred_res_all)\n",
        "predicted_career_labels = mlb_career.inverse_transform(y_pred_career_all)\n",
        "\n",
        "# Add predicted labels to the DataFrame\n",
        "df['predicted_resource_labels'] = predicted_resource_labels\n",
        "df['predicted_career_labels'] = predicted_career_labels\n",
        "\n",
        "# Show the DataFrame with predicted labels\n",
        "df[['full_text', 'predicted_resource_labels', 'predicted_career_labels']]"
      ],
      "metadata": {
        "id": "P0ffJ7iwsFyK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Multi-label Binary Classification"
      ],
      "metadata": {
        "id": "ZzTEVvZ3NcKk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Vectorize the text\n",
        "tfidf = TfidfVectorizer(stop_words='english', max_features=1000)\n",
        "X = tfidf.fit_transform(df['full_text'])\n",
        "\n",
        "# Keep tweet_id as a separate variable\n",
        "tweet_ids = df['tweet_id']\n",
        "\n",
        "# Split data for both resource and career areas, ensuring tweet_id stays aligned\n",
        "X_train_res, X_test_res, y_train_res, y_test_res, tweet_ids_train_res, tweet_ids_test_res = train_test_split(\n",
        "    X, y_resource, tweet_ids, test_size=0.2, random_state=42\n",
        ")\n",
        "X_train_career, X_test_career, y_train_career, y_test_career, tweet_ids_train_career, tweet_ids_test_career = train_test_split(\n",
        "    X, y_career, tweet_ids, test_size=0.2, random_state=42\n",
        ")\n",
        "\n",
        "# Train multi-label classifier for resource type using Logistic Regression\n",
        "resource_model = MultiOutputClassifier(LogisticRegression(max_iter=200))\n",
        "resource_model.fit(X_train_res, y_train_res)\n",
        "\n",
        "# Train multi-label classifier for career area using Logistic Regression\n",
        "career_model = MultiOutputClassifier(LogisticRegression(max_iter=200))\n",
        "career_model.fit(X_train_career, y_train_career)\n",
        "\n",
        "# Predict on the test set\n",
        "y_pred_res = resource_model.predict(X_test_res)\n",
        "y_pred_career = career_model.predict(X_test_career)\n",
        "\n",
        "# Combine predictions with tweet IDs for easy joining\n",
        "resource_results = pd.DataFrame(y_pred_res, columns=mlb_resource.classes_)\n",
        "resource_results['tweet_id'] = tweet_ids_test_res.values\n",
        "career_results = pd.DataFrame(y_pred_career, columns=mlb_career.classes_)\n",
        "career_results['tweet_id'] = tweet_ids_test_career.values\n",
        "\n",
        "# Display classification reports for both models\n",
        "print(\"Resource Type Classification Report\")\n",
        "print(classification_report(y_test_res, y_pred_res, target_names=mlb_resource.classes_))\n",
        "\n",
        "print(\"\\nCareer Area Classification Report\")\n",
        "print(classification_report(y_test_career, y_pred_career, target_names=mlb_career.classes_))"
      ],
      "metadata": {
        "id": "Q0agEmWnuRNM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Accuracy:** 95% for Resource Type (samples avg), 79% for Career Area (samples avg).\n",
        "\n",
        "**Strengths:** High precision across most Resource Type categories, strong performance on popular Career Area labels like AI, Tech, and general_discussion.\n",
        "\n",
        "**Weaknesses:** Lower recall for underrepresented Career Area categories, such as Finance, GovTech, and Non-Tech.\n",
        "\n",
        "**Interpretation:** This multi-label binary approach captures frequent categories well and can handle multiple labels per tweet, but would benefit from more data for less common labels and potentially further tuning.\n",
        "\n",
        "**Recommendation:** Model 4 shows robust multi-label capabilities, making it the most versatile and accurate choice among the models tested."
      ],
      "metadata": {
        "id": "uPVoGIQ0MDKT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Final combined results with tweet_id to facilitate joining\n",
        "final_results = pd.merge(resource_results, career_results, on=\"tweet_id\", suffixes=('_resource', '_career'))\n",
        "final_results.head()"
      ],
      "metadata": {
        "id": "PDTO_ZfavnWQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Predict labels for the entire original dataset without filtering\n",
        "y_pred_res_all = resource_model.predict(X)\n",
        "y_pred_career_all = career_model.predict(X)\n",
        "\n",
        "# Convert predicted labels back to their original format\n",
        "predicted_resource_labels = mlb_resource.inverse_transform(y_pred_res_all)\n",
        "predicted_career_labels = mlb_career.inverse_transform(y_pred_career_all)\n",
        "\n",
        "# Add predicted labels back to the original DataFrame\n",
        "df['predicted_resource_labels'] = predicted_resource_labels\n",
        "df['predicted_career_labels'] = predicted_career_labels\n",
        "\n",
        "# Display the DataFrame with tweet_id, full_text, and predicted labels\n",
        "df_with_predictions = df[['tweet_id', 'full_text', 'predicted_resource_labels', 'predicted_career_labels']]\n",
        "df_with_predictions"
      ],
      "metadata": {
        "id": "l3JWLsX8viV5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Remove general_discussion Labels"
      ],
      "metadata": {
        "id": "ni3Y50rnrVrA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Filter out rows where 'general_discussion' appears in predicted labels\n",
        "df_filtered = df[~df['predicted_resource_labels'].apply(lambda x: 'general_discussion' in x)].copy()\n",
        "df_filtered_with_predictions = df_filtered[~df_filtered['predicted_career_labels'].apply(lambda x: 'general_discussion' in x)].copy()\n",
        "\n",
        "# Display tweet_id, full_text, and predicted labels without general_discussion\n",
        "df_filtered_with_predictions[['tweet_id', 'full_text', 'predicted_resource_labels', 'predicted_career_labels']]\n",
        "df_filtered_with_predictions"
      ],
      "metadata": {
        "id": "fir2En-DvSxI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# prompt: df_with_predictions to csv name classified_tweets\n",
        "\n",
        "# Assuming df_with_predictions is already defined as in your code\n",
        "\n",
        "df_with_predictions.to_csv('/content/drive/MyDrive/TwitterLinkedIn_AI_ML_Project/classified_tweets.csv', index=False)"
      ],
      "metadata": {
        "id": "m4uG2j_Sw2ZR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_filtered_with_predictions.to_csv('/content/drive/MyDrive/TwitterLinkedIn_AI_ML_Project/classified_filtered_tweets.csv', index=False)"
      ],
      "metadata": {
        "id": "dqXkt40auKXI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Suggested Improvements:**\n",
        "\n",
        "**Increase Sample Diversity:** If possible, gather more labeled examples, especially for underrepresented categories in Career Area (e.g., \"Finance,\" \"Non-Tech\").\n",
        "\n",
        "**Data Augmentation:** For Career Area classes with low samples, consider synthetic data generation (e.g., paraphrasing techniques) to balance class distribution.\n",
        "\n",
        "**Use Pre-trained Embeddings:** Switch to embeddings (e.g., BERT or TF-IDF with n-grams) to capture more context in tweets, which may help distinguish nuanced Career Area labels.\n",
        "\n",
        "**Recommended Model:**\n",
        "\n",
        "Model 3 is the most promising due to its multi-label approach and balanced performance across Resource Type and Career Area. Further tuning and potentially more data can improve Career Area classification for low-sample classes."
      ],
      "metadata": {
        "id": "AOxZWsxVLq3Y"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "save_and_push_to_github(\"Twitter Classification Update\")"
      ],
      "metadata": {
        "id": "COhlgupFFDl4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Analysis\n",
        "\n",
        "Model 4 uses a multi-label binary approach to handle multiple labels per tweet across both `Resource Type` and `Career Area`. This approach provides a high degree of flexibility in classification, allowing for a more nuanced understanding of tweets that might cover multiple categories.\n",
        "\n",
        "#### Resource Type Classification Report\n",
        "\n",
        "- **High Precision and Recall**:\n",
        "   - The model performs exceptionally well for high-frequency categories like `general_discussion` (f1-score: 0.98), `bootcamp` (f1-score: 0.90), and `upskilling` (f1-score: 0.95).\n",
        "   - This suggests that the model can effectively identify tweets that fit into one or more commonly occurring resource types.\n",
        "  \n",
        "- **Challenges with Moderate-Frequency Labels**:\n",
        "   - Labels such as `resume` (f1-score: 0.70) and `conferences` (f1-score: 0.70) show slightly lower performance, likely due to fewer samples, leading to a lower recall despite high precision.\n",
        "\n",
        "- **Overall Performance**:\n",
        "   - The micro average f1-score of 0.95 and samples average recall of 0.95 indicate robust performance for multi-label classification, suggesting that this model captures resource types effectively across diverse tweet content.\n",
        "\n",
        "#### Career Area Classification Report\n",
        "\n",
        "- **High Precision but Varying Recall**:\n",
        "   - Categories with abundant data, like `Tech`, `AI`, and `general_discussion`, show strong precision and moderate-to-high recall, achieving an f1-score of 0.88 for `general_discussion`.\n",
        "   - Other popular categories such as `Cloud`, `Cybersecurity`, and `Data` also show satisfactory results, indicating that the model has learned to identify these specific fields reliably.\n",
        "\n",
        "- **Low Recall for Less Common Labels**:\n",
        "   - Categories like `Finance`, `GovTech`, and `Non-Tech` have low recall scores (e.g., `Finance` recall: 0.12), which suggests that more data or enhanced feature engineering may be needed to improve classification accuracy for these areas.\n",
        "   - Labels with minimal representation, such as `Digital Marketing` and `Product Design`, have low performance metrics, primarily due to data scarcity.\n",
        "\n",
        "- **Macro vs. Micro Averages**:\n",
        "   - The micro average f1-score of 0.80 and samples average recall of 0.78 indicate good model performance in predicting multiple career areas simultaneously.\n",
        "   - However, the lower macro-average scores reveal that underrepresented categories could benefit from targeted improvements.\n",
        "\n",
        "### Key Takeaways\n",
        "\n",
        "1. **High Overall Performance**: Model 4 performs well in multi-label classification, especially for frequently occurring categories in both `Resource Type` and `Career Area`. This setup provides the flexibility to predict multiple labels per tweet, better reflecting real-world tweet content.\n",
        "   \n",
        "2. **Areas for Improvement**:\n",
        "   - **Class Balancing**: Enhancing class representation by collecting more examples for underrepresented labels like `Finance`, `GovTech`, and `Non-Tech`.\n",
        "   - **Feature Engineering**: Adding additional features or using embeddings (e.g., BERT or DistilBERT) could improve classification for nuanced categories with overlapping terminology.\n",
        "   - **Threshold Optimization**: Experimenting with classification thresholds might improve recall for categories where precision is already high.\n",
        "\n",
        "### Recommended Approach\n",
        "Model 4’s multi-label binary classification approach is the most promising, as it effectively handles multiple overlapping categories and provides high accuracy on well-represented labels. Refining this model further with the above improvements will likely yield the best overall performance across both `Resource Type` and `Career Area`."
      ],
      "metadata": {
        "id": "bVjU3It-M9z5"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Given the structural similarity between **Model 3** and **Model 4**, their differences in performance can be primarily attributed to the inclusion of `tweet_id` tracking in **Model 4**, which does not directly impact classification accuracy or F1-score. Here’s how their performance and functionality compare:\n",
        "\n",
        "### Performance Analysis:\n",
        "\n",
        "- **Accuracy and F1-Scores**:\n",
        "  - Both models yield similar performance metrics across `Resource Type` and `Career Area` categories, as they use the same multi-label setup with `LogisticRegression` under `MultiOutputClassifier`.\n",
        "  - Model 3 and Model 4 share near-identical precision, recall, and F1-scores, with **Model 4 achieving slightly better organization and tracking of outputs** but not improving classification accuracy.\n",
        "\n",
        "### Functionality and Utility:\n",
        "\n",
        "- **Model 3**:\n",
        "  - Provides a straightforward approach to classification, useful for **evaluating aggregate metrics** without needing to track individual predictions at the tweet level.\n",
        "  - **Limitation**: Lacks a way to map predictions back to individual `tweet_id`s, making it challenging to analyze or save results per tweet.\n",
        "\n",
        "- **Model 4**:\n",
        "  - Includes `tweet_id` in the data split, allowing each prediction to be mapped back to its respective tweet. This adds flexibility for **post-prediction analysis** or **joining predictions back with the original data** for further insights.\n",
        "  - **Benefit**: Maintains comparable accuracy while enabling **tweet-specific tracking**, facilitating applications where results need to be stored, displayed, or updated on a per-tweet basis.\n",
        "\n",
        "### Summary:\n",
        "While both models perform similarly in classification tasks, **Model 4** stands out for its ability to track predictions by `tweet_id`. This makes Model 4 more suitable for projects where individualized tweet analysis is important, while **Model 3** remains a simpler option when only aggregate performance metrics are needed."
      ],
      "metadata": {
        "id": "lJcG_EG-RIWK"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# LinkedIn"
      ],
      "metadata": {
        "id": "ICNtQc5Pxarn"
      }
    }
  ]
}